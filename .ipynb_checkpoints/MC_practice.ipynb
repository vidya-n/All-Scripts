{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#armstrong check\n",
    "i = input('Give any number to check if it is an Armstrong: ')\n",
    "n = len(i)\n",
    "sum = 0\n",
    "\n",
    "for digit in i:\n",
    "    sum += int(digit) ** n\n",
    "\n",
    "if sum == int(i):\n",
    "    print(f\"{i} is an Armstrong number.\")\n",
    "else:\n",
    "    print(f\"{i} is not an Armstrong number.\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking scrabble score\n",
    "score = {\"a\": 1, \"c\": 3, \"b\": 3, \"e\": 1, \"d\": 2, \"g\": 2, \n",
    "         \"f\": 4, \"i\": 1, \"h\": 4, \"k\": 5, \"j\": 8, \"m\": 3, \n",
    "         \"l\": 1, \"o\": 1, \"n\": 1, \"q\": 10, \"p\": 3, \"s\": 1, \n",
    "         \"r\": 1, \"u\": 1, \"t\": 1, \"w\": 4, \"v\": 4, \"y\": 4, \n",
    "         \"x\": 8, \"z\": 10}\n",
    "\n",
    "def scrabble_score(word):\n",
    "    wordlow = str(word.lower())\n",
    "    score1 = 0\n",
    "    leng = len(wordlow)\n",
    "    for i in range(0, leng):\n",
    "        score1 += score[wordlow[i]]\n",
    "    print(f\"Scrabble score of \\\"{word}\\\" is {score1}.\")\n",
    "    return score1\n",
    "\n",
    "inp = input(\"Enter the word to check its scrabble score: \")\n",
    "print(\"\\n\")\n",
    "scrabble_score(inp)\n",
    "p = input(\"\\n\\nEnter any key to exit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doctor urls for single page\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://www.arh.org/providers/?jet-smart-filters=epro-posts/default&_tax_query_post_city=96\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "#print(response.status_code)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    # Extract the desired data from the parsed HTML\n",
    "    # Example: Extract all the links on the page\n",
    "    links = [link.get(\"href\") for link in soup.find_all(\"a\", class_=\"elementor-button-link elementor-button elementor-size-md\")]\n",
    "    print(links)\n",
    "    \n",
    "else:\n",
    "    print(\"Failed to retrieve data from the URL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unfinished - extracting links from all pages.\n",
    "#To Do - Resolve iframe issue\n",
    "\n",
    "# Doctor urls for multiple pages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#domain = \"https://doctors.summithealthcare.net/find_a_doctor/\"\n",
    "\n",
    "doctor_names = []\n",
    "doctor_urls = []\n",
    "for i in range(1, 104):\n",
    "    url = 'https://doctors.valleyhealth.com/search?sort=networks%2Crelevance%2Cavailability_density_best&page=1'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    doctors = soup.find_all('div', {'data-view': 'consumer-provider'})\n",
    "    #print(doctors)\n",
    "\n",
    "    for doctor in doctors:\n",
    "        for link in doctor.find_all(\"a\"):\n",
    "            print(link.text.strip()) # print the text of the link\n",
    "            print(link['href'])     # print the href of the link\n",
    "    \n",
    "print(f\"Page {i} done\")\n",
    "\n",
    "#print(len(doctor_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract doctor urls from pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "domain  = \"https://www.adventhealth.com\"\n",
    "doctor_urls = []\n",
    "\n",
    "for i in range(1, 27):\n",
    "    search = \"https://www.adventhealth.com/hospital/adventhealth-wesley-chapel/find-doctors\"\n",
    "\n",
    "    response = requests.get(search)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    #print(soup.prettify())\n",
    "\n",
    "    doctors = soup.find_all('div', {'class': 'physician-block__cta'})\n",
    "    #print(len(doctors))\n",
    "    \n",
    "\n",
    "    for doctor in doctors:\n",
    "        for link in doctor.find_all('a', href=True):\n",
    "            doctor_urls.append(domain + link['href'])\n",
    "    #print(f\"Page {i} done\")\n",
    "print(len(doctor_urls))\n",
    "print(doctor_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "\n",
    "testlink = doctor_urls[0]\n",
    "\n",
    "r = requests.get(testlink) \n",
    "tree = html.fromstring(r.content)\n",
    "soup = BeautifulSoup(r.content, 'html.parser')\n",
    "\n",
    "name = soup.find('h1', {'class': 'physician-details-block__name'}).text.strip() \n",
    "specialty = soup.find_all('p', {'class': 'physician-details-block__specialty'}) \n",
    "address = {} \n",
    "add_count = len(tree.xpath('//div[contains(@class, \"physician-locations-block__locations-item\")]'))\n",
    "\n",
    "practice_name = tree.xpath('//div[contains(@class, \"__locations-item\")]//div[contains(@class, \"practice-name\")]/text()')\n",
    "addresses = tree.xpath('//div[contains(@class, \"physician-locations-block__practice-name\")]/following-sibling::div[1]//span[contains(@property, \"streetAddress\")]/text()')\n",
    "city = list(soup.find_all('span', {'property': 'addressLocality'}))\n",
    "state = list(soup.find_all('span', {'property': 'addressRegion'}))\n",
    "zip = list(soup.find_all('span', {'property': 'postalCode'}))\n",
    "phone = tree.xpath('//div[contains(@class, \"physician-locations-block__telephone\")]/a/span/following-sibling::text()')\n",
    "\n",
    "\n",
    "\"\"\"for i in range(add_count):\n",
    "    address[i] = {\n",
    "        'practice_name': practice_name[i].text.strip(),\n",
    "        'address': addresses[i],\n",
    "        'city': city[i].text.strip(),\n",
    "        'state': state[i].text.strip(),\n",
    "        'zip': zip[i].text.strip(),\n",
    "        'phone': phone[i]\n",
    "    }\"\"\"\n",
    "\n",
    "print(practice_name)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
